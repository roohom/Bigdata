# kafka

## 消息队列

### 消息队列MQ

- 消息队列：Message queue
- 定义：用于在两个消息系统或者模块之间实现消息数据的缓存，通过队列的方式实现数据传输
- 问题：实际业务中访问服务器的请求并发量过大，会导致服务故障，或者请求丢失等等，无法确保每一条数据都被处理，怎么解决？
  - 解决：引入消息队列，不侧重于性能，而侧重于保证最终每一条请求都被处理了，将大量的数据放入消息队列：先进先出，先生成，先被处理

### 同步与异步

- 消息队列在整体的业务模式上是异步模式

- 有一些场景下不能使用异步来实现业务需求
- 业务流程的同步与异步
  - 同步：用户看到的结果就是最后的结果
    - 用户提交需求，后台处理需求，将处理的结果返回给用户
  - 异步：用户看到的结果还不是最后的结果
    - 用户提交需求，后台直接返回临时结果，后台再处理这个请求
- 数据传输的同步与异步
  - 同步
    - A给B发送数据，B确认收到之后，A再发下一条
    - TCP协议
      - 特点：慢，数据安全的**三次握手**
  - 异步
    - A给B发送第一条数据，不管B有没有收到，就发送第二条
    - UDP协议
      - 特点：快，数据易丢失

### 应用场景

- 解耦
- 异步处理
  - 降低数据都市或者应用故障的风险
  - 允许并发对消息系统中的数据进行读写
- 限流削峰
  - 避免峰值资源分配的不合理
- 构建消息系统
  - 系统A -> 消息队列 -> 系统B -> 消息队列 -> 系统C

### 缺点

- 必须保证消息队列的稳定及安全性
  - 一旦消息队列故障，整个系统全部瘫痪
  - 如果机器故障？
    - 需要构建分布式消息队列：多台机器的集群，如果有任何一台机器故障，其他机器仍然可以提供服务
  - 如何保证数据丢失，照样可以消费？
    - HDFS：副本
    - Hbase：WAL+HDFS副本
- 运维更加复杂
  - 生产者：向消息队列中发送写入数据
  - 消费者：向消息队列中消费读取数据
  - 必须确保生产到消息队列之间的数据安全
  - 必须确保消费者消费消息队列的数据安全
    - **如何避免出现数据重复或者数据丢失的问题？**
      - 必须保证：**生产者的数据在消息队列中只存储一份**
      - 必须保证：**消费者消费消息队列中的数据，只成功消费一次**
      - 最终保证：一次性语义
        - 至少一次：数据重复问题
        - 至多一次：数据丢失问题
        - 仅有一次：只有1次

### 消息队列的两种模式

- 点对点模式
  - 角色
    - 生产者
    - 消费者
    - 消息队列
  - 特点：如果消费者消费完这条数据会给消息队列一个确认，消息队列一旦收到这个确认，就会删除这条数据
  - 问题：消息队列中的数据不能共享，只能有一个消费者进行消费
- 订阅发布模式
  - 角色
    - 生产者
    - 消费者
    - 消息队列：主题Topic
  - 特点：允许多个生产者、主题、消费者、能实现数据共享，并且可以随机地添加生产者和消费者

## Kafka的介绍和以及应用

### 功能

- 定义：分布式的基于订阅发布模式的消息队列系统
- 流式存储、流式计算
- 应用：实时存储来解决大数据实时架构中的数据缓存的问题

### 特点

- 分布式：解决高并发、存储、故障冗余的问题
- 高吞吐量：分布式

- 可扩展的高性能：上千台机器的集群，每天上万亿级别的数据存储
- 高容错：数据不会丢失，避免数据的丢失与重复
- 高可用：分布式架构，多台机器，副本机制

### 特殊概念

- 生产者：Producer

  - 用于往kafka的Topic中生产数据
  - 实际工作中都是**数据采集工具**

- 消费者/消费者组：Consumer

  - 用于从kafka的Topic中消费数据

  - 实际工作中：一般都是分布式流式计算程序：SparkStreaming、Flink

    > 注意：kafka中以消费者组为单位来实现数据的消费
    >
    > - 任何一个消费者必然属于某一个消费者组
    > - 一个消费者组中可以包含多个消费者
    > - 一个消费者组消费一份数据：如果一个组内有多个消费者，所有消费者消费的数据加在一起是一份完整的数据

- Broker：一个Broker就是一个Kafka节点

  - 多个Broker构建Kafka集群
  
- Topic：主题

  - 用于区分不同的数据的存储
    - 生产者将不同的数据生产到不同对Topic
    - 消费者根据需求从不同的Topic中消费数据

- Partition：分区

  - 类似于HBASE中的Region
  - 一个Topic需要构建分布式存储，就会构建多个分区
  - 不同的分区可以存储在不同的kafka节点上，实现分布式存储
  - 分区规则：
    - HDFS：文件：Block
      - 按照大小：128M
    - Hbase：表：Region
      - 按照范围：rowkey数据哪个区间(region)就写入对应的region
    - Kafka：Topic：Partition
      - 多种分区规则

- Replication：分区副本 
  - 每个分区可以构建对应的副本分区
  - 例如：创建三个分区，构建两个副本
  - 总共：存储6个分区
  - 同一个分区的相同副本不能在同一台机器
  - **分区的副本数不允许超过机器数**
  - **问题：一个分区有读个副本，在读写时，往哪个副本读写呢？**
    - 解决：Kafka中将一个分区的读个副本构建主从角色
      - 主副本分区：负责接收生产者和消费的读写请求
      - 从副本分区：负责与主副本分区同步数据
        - 如果主副本丢失或故障，从副本会重新选举一个新的主副本
        - 依赖于Zookeeper实现选举
    - 无论是主副本分区还是从副本分区，都是分区，且数据相同

- Segment：分区段，对这个分区的数据更细的划分
  - 按照数据写入的时间先后进行划分
  - 类似于HBASE中的Store，对整个分区的数据再进行划分
  - 每个segment包含一对文件
    - .log文件
    - .index文件
  - .Log：写入Kafka的数据存储在.log文件中
  - .index：与.log文件成对出现，文件名称一致
    - 对应.log文件的索引
    - 每次读取数据先读.index索引，根据索引信息再读.log文件
- Offset：数据在分区中的偏移量
  - **功能：标记消费者消费数据的位置，当消费者故障，根据上一次消费者消费到的位置，从上次消费的位置继续消费**
  - 每个Topic的每个分区的偏移量是独立的
  - 每个分区写入的第一条数据的偏移量是从0开始的
    - 生产：按照数据写入分区的顺序来标记偏移量

    - 消费：指定偏移量进行消费

    - 举个栗子

      - Topic

        - part0
        - part1
        - part2

      - 生产者：写数据

        - 按照分区规则将数据写入对应分区

        - part0

          ```
          0		hadoop   Redis
          1		spark
          2		flink
          ```

        - part1

          ```
          0		hive
          1		hue
          ```

        - part2

          ```
          0		hbase
          1		oozie
          ```

      - 消费者：读数据

        - 按照每个分区的offset来进行消费的

        - part0：1

          ```
          hadoop    Redis
          ```

        - part1:1

          ```
          hive
          ```

        - part2：1

          ```
          hbase
          ```


### 架构

- Hbase：Table：Region：Store：mem&storefile
- Kakfa：Topic：Partition：Segment：.log & .index
- 架构
  - Kafka Broker：Kafka节点
  - Zookeeper
    - 辅助选举：分区副本主从选举
    - Kafka的元数据：所有kafka节点信息、Topic的信息、分区的信息
  - Kafka也是分布式主从架构
    - Kafka所有节点的进程都叫Kafka，任何一个Kafka节点都可以接受请求
    - 主：Kafka Controler：管理
    - 从：Broker